<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Style-Type" content="text/css" />
    <meta name="generator" content="pandoc" />
    <title>Solution Writeup: Pillage Twilight Heroes</title>
    <style type="text/css">code{white-space: pre;}</style>
    <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    </style>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

    <link rel="stylesheet" href="/style/editorials.css" type="text/css">

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <!-- <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> -->

    <script>
        var tooltipTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]'))
        var tooltipList = tooltipTriggerList.map(function (tooltipTriggerEl) {
          return new bootstrap.Tooltip(tooltipTriggerEl)
        })
    </script>

    </head>
<body class="body">

<!--

<div id="header">
<h1 class="title">Solution Writeup: Pillage Twilight Heroes</h1>
</div>

-->


<div class="editorial container">
<h1 id="pillage-twilight-heroes">Pillage Twilight Heroes</h1>
<h2 id="solution-writeup">Solution Writeup</h2>
<p><strong>Contest:</strong> <a href="https://noi.ph/tama-2023/">TAMa 2023</a><br />
<strong>Problem Idea:</strong> Cassidy Tan<br />
<strong>Testing:</strong> Vincent dela Cruz<br />
<strong>Statement:</strong> Cisco Ortega<br />
<strong>Test Data Preparation:</strong> Kevin Atienza<br />
<strong>Solution Writeup:</strong> Kevin Atienza</p>
<div class="editorial-section">
<h2 id="remark-ab-modulo-998244353">Remark: <span class="math inline">\(a/b\)</span> modulo <span class="math inline">\(998244353\)</span>?</h2>
<p>In this editorial, I'll pretend that we're <em>computing the full answer</em> (a rational number) instead of <em>the answer modulo <span class="math inline">\(998244353\)</span></em>. It turns out that many exact solutions can be adapted to compute the answer modulo something instead. A bonus section below describes how to do it.</p>
</div>
<p><details class="editorial-section"><summary class="h2">Subtask 1</summary></p>
<p>For Subtask 1, I'll describe a solution that doesn't use a lot of insights and essentially only uses <strong>dynamic programming</strong> (DP) (aside from the definition of <a href="https://en.wikipedia.org/wiki/Expected_value">expected value</a>). You could also solve this subtask with <em>pen and paper</em> by using the solution for Subtask 2, which is perfectly doable by hand (and easier to implement as well).</p>
<h3 id="expected-value-counting">Expected value ⇝ Counting</h3>
<p>If you have some sort of “random variable” <span class="math inline">\(X\)</span>, then we say that the <strong>expected value</strong> of <span class="math inline">\(X\)</span>, denoted <span class="math inline">\(\operatorname{E}[X]\)</span>, is the weighted sum of the possible results of <span class="math inline">\(X\)</span>, weighted by their probabilities. More formally, if the possible results are <span class="math inline">\(\{x_1, x_2, \ldots, x_k\}\)</span> with respective probabilities <span class="math inline">\(p_1, p_2, \ldots, p_k\)</span>, then <span class="math display">\[\operatorname{E}[X] := p_1x_1 + p_2x_2 + \ldots + p_kx_k,\]</span> or in summation notation, <span class="math display">\[\operatorname{E}[X] := \sum_{i=1}^k p_ix_i.\]</span> The expected value of <span class="math inline">\(X\)</span> can be thought of as the <em>average</em> value of <span class="math inline">\(X\)</span>, when an experiment is performed many, many times and averaging the value of <span class="math inline">\(X\)</span> across them.</p>
<p>Here are some examples:</p>
<ul>
<li>If <span class="math inline">\(X\)</span> represents the result of throwing a die, then the possible results are <span class="math inline">\(\{1, 2, \ldots, 6\}\)</span>, each with probability <span class="math inline">\(1/6\)</span>, so the expected value is <span class="math display">\[\operatorname{E}[X] = \frac{1}{6}\cdot 1 + \frac{1}{6}\cdot 2 + \ldots + \frac{1}{6}\cdot 6 = \frac{1}{6}(1 + 2 + \ldots + 6) = \frac{21}{6} = 3.5.\]</span></li>
<li>If <span class="math inline">\(Y\)</span> represents the <em>sum</em> of the results of throwing two dice, then the possible results are <span class="math inline">\(\{2, 3, 4, \ldots, 12\}\)</span>. The probabilities are no longer uniform, e.g., <span class="math inline">\(7\)</span> is much more probable than <span class="math inline">\(2\)</span> or <span class="math inline">\(12\)</span>. The full table of probabilities is: <span class="math display">\[\begin{array}{r|ccccccccccc}
\text{result}      &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10 &amp; 11 &amp; 12 \\
\hline
\text{probability} &amp; \frac{1}{36} &amp; \frac{2}{36} &amp; \frac{3}{36} &amp; \frac{4}{36} &amp; \frac{5}{36} &amp; \frac{6}{36} &amp; \frac{5}{36} &amp; \frac{4}{36} &amp; \frac{3}{36} &amp; \frac{2}{36} &amp; \frac{1}{36}
\end{array}\]</span> and you can check that the expected value of <span class="math inline">\(Y\)</span> is <span class="math display">\[\operatorname{E}[Y] = \frac{252}{36} = 7.\]</span></li>
</ul>
<p>So let's define a random variable <span class="math inline">\(T\)</span> representing the result of the process outlined in the problem statement. The process chooses <span class="math inline">\(w\)</span> numbers randomly<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> between <span class="math inline">\(1\)</span> and <span class="math inline">\(k\)</span>, and <span class="math inline">\(T\)</span> is calculated as the <em>sum</em> of the <span class="math inline">\(n\)</span> largest elements, so the possible results are between <span class="math inline">\(n\)</span> and <span class="math inline">\(nk\)</span>. If we write the probability of obtaining the result <span class="math inline">\(t\)</span> as <span class="math inline">\(p_t\)</span>, then the answer is <span class="math display">\[\operatorname{E}[T] = \sum_{t=n}^{nk}\, p_t\,t.\]</span> So we are done if we can compute <span class="math inline">\(p_t\)</span> for each <span class="math inline">\(t\)</span> from <span class="math inline">\(n\)</span> to <span class="math inline">\(nk\)</span>.</p>
<p>Now, the process has <span class="math inline">\(k^w\)</span> possible outcomes—namely all the sequences of length <span class="math inline">\(w\)</span>, each element of which is between <span class="math inline">\(1\)</span> and <span class="math inline">\(k\)</span>—and each of those outcomes is equally likely. Therefore, we can simply <em>count</em> the number of outcomes that result in a sum of <span class="math inline">\(t\)</span>, then divide by <span class="math inline">\(k^w\)</span> to get the probability. If we write the <em>number</em> of sequences whose sum of <span class="math inline">\(n\)</span> largest elements is <span class="math inline">\(t\)</span> as <span class="math inline">\(c_t\)</span>, then we simply have <span class="math display">\[p_t = \frac{c_t}{k^w}.\]</span></p>
<p>So we've now reduced the problem to computing the <span class="math inline">\(c_t\)</span>s. Now, a sum of <span class="math inline">\(t\)</span> can arise in multiple ways. For example, if <span class="math inline">\(n = 3\)</span> and <span class="math inline">\(t = 10\)</span>, then the top <span class="math inline">\(3\)</span> values of the sequence (each in sorted order) could be <span class="math inline">\([2, 3, 5]\)</span>, or it could be <span class="math inline">\([2, 4, 4]\)</span>, or <span class="math inline">\([1, 1, 8]\)</span>, or something else. So, to count the number of sequences whose sum of <span class="math inline">\(n\)</span> largest elements is <span class="math inline">\(t\)</span>, we need to enumerate all possible sequences of top <span class="math inline">\(n\)</span> values whose sum is <span class="math inline">\(t\)</span>, and for each one, count the number of sequences of length <span class="math inline">\(w\)</span> whose sequence of top <span class="math inline">\(n\)</span> values is <em>that</em> sequence.</p>
If that's confusing, let's formalize a bit. Let's define a <strong>winner sequence</strong> as a <em>sorted</em> sequence of <span class="math inline">\(n\)</span> values, each of which is between <span class="math inline">\(1\)</span> and <span class="math inline">\(k\)</span>. Winner sequences are exactly the possible “sequences of <span class="math inline">\(n\)</span> largest values”. Now, if <span class="math inline">\(W\)</span> is a winner sequence, let's define <span class="math inline">\(c(W, w)\)</span> as the number of length-<span class="math inline">\(w\)</span> sequences whose sequence of <span class="math inline">\(n\)</span> largest values is <span class="math inline">\(W\)</span>. Then you may check that the following equation holds <span class="math display">\[c_t = \sum_{\substack{\text{$W$ is a winner sequence} \\ \mathit{sum}(W) = t}} c(W, w).\]</span> Thus, we've further reduced the problem to that of computing <span class="math inline">\(c(W, w)\)</span> across all winner sequences <span class="math inline">\(W\)</span>. And as it turns out, for Subtask 1, there aren't that many winner sequences. We can see this by simply enumerating them all (say with a computer). Finding a formula for the number of them isn't that hard either:
<div class="task">
<p><strong>Exercise:</strong> Show that the number of winner sequences is exactly <span class="math inline">\(\binom{n + k - 1}{n}\)</span>.</p>
</div>
<p>For Subtask 1, <span class="math inline">\(n = 5\)</span> and <span class="math inline">\(k = 5\)</span>, so <span class="math inline">\(\binom{n + k - 1}{n} = 126\)</span>, so there are indeed only a few of them.</p>
<h3 id="computing-cw-w">Computing <span class="math inline">\(c(W, w)\)</span></h3>
<p>Thinking “DP-cally”, we now attempt to build the length-<span class="math inline">\(w\)</span> sequence element by element. As we build the sequence, its “sequence of <span class="math inline">\(n\)</span> largest elements” changes as well.</p>
<p>Let's be more precise. For a sequence <span class="math inline">\(S\)</span>, let's call the “sequence of <span class="math inline">\(n\)</span> largest elements of <span class="math inline">\(S\)</span>” its <strong>winning sequence,</strong> and denote it by <span class="math inline">\(W_S\)</span>. Now, suppose we insert the value <span class="math inline">\(v\)</span> to <span class="math inline">\(S\)</span>. Let's denote the updated sequence by <span class="math inline">\(S + [v]\)</span>. Then the winning sequence might change because of <span class="math inline">\(v\)</span>. Specifically, the new winning sequence is obtained by <em>inserting</em> <span class="math inline">\(v\)</span> to <span class="math inline">\(W_S\)</span> in its proper sorted location, and then dropping the lowest element. (Can you see why?) Let's denote the process of “inserting a value <span class="math inline">\(v\)</span> to a sequence <span class="math inline">\(W\)</span> in its proper sorted location, and then dropping the lowest element” as a <em>pushpop</em> operation, and denote it by <span class="math inline">\(\mathit{pushpop}(W, v)\)</span>. Then what we're saying is that the winning sequence of <span class="math inline">\(S + [v]\)</span> is related to the winning sequence of <span class="math inline">\(S\)</span> via a pushpop operation—specifically, <span class="math display">\[W_{S + [v]} = \mathit{pushpop}(W_S, v).\]</span></p>
<p>We can now think recursively, and find a recurrence for <span class="math inline">\(c(W, w)\)</span>, as follows. Every sequence of length <span class="math inline">\(w\)</span> can be obtained by taking a sequence <span class="math inline">\(S\)</span> of length <span class="math inline">\(w - 1\)</span> and then appending some value <span class="math inline">\(v\)</span> (between <span class="math inline">\(1\)</span> to <span class="math inline">\(k\)</span>) to it. And as described above, the new winning sequence <span class="math inline">\(W_{S + [v]}\)</span> is just <span class="math inline">\(\mathit{pushpop}(W_S, v)\)</span>. Notice that this latter expression only depends on <span class="math inline">\(W_S\)</span>, not on <span class="math inline">\(S\)</span> itself. Thus, for each possible <em>winner</em> sequence <span class="math inline">\(W&#39;\)</span>, we could simply collect the sequences <span class="math inline">\(S\)</span> with <span class="math inline">\(W&#39;\)</span> as their winning sequence, and notice that the new winning sequence must be <span class="math inline">\(\mathit{pushpop}(W&#39;, v)\)</span>. In other words, we have the equation <span class="math display">\[c(W, w) = \!\!\!\!\sum_{\substack{W&#39;\,\,\,\, \\ \text{$W&#39;$ is a winner sequence}}} \sum_{\substack{1 \le v \le k \,\,\,\, \\ \mathit{pushpop}(W&#39;, v) = W}} \!\!\!\!(\text{number of sequences $S$ of length $w - 1$ whose winning sequence is $W&#39;$}).\]</span> But the summand is just <span class="math inline">\(c(W&#39;, w - 1)\)</span> by definition! Therefore, we obtain the recurrence <span class="math display">\[c(W, w) = \sum_{\substack{W&#39;\,\,\,\, \\ \text{$W&#39;$ is a winner sequence}}} \sum_{\substack{1 \le v \le k \,\,\,\, \\ \mathit{pushpop}(W&#39;, v) = W}} c(W&#39;, w - 1),\]</span> and we can use this to compute all <span class="math inline">\(c(W, w&#39;)\)</span> we need, via DP: we build a <em>table</em> of results, one for each winner sequence <span class="math inline">\(W\)</span> and each <span class="math inline">\(w&#39; \le w\)</span>. Each entry of the table can be computed using the summation above. Since our formula for <span class="math inline">\(c(W, w&#39;)\)</span> only depends on <span class="math inline">\(c(W&#39;, w&#39; - 1)\)</span>, i.e., those with a smaller <span class="math inline">\(w&#39;\)</span> value, if we compute the table in increasing order of <span class="math inline">\(w&#39;\)</span>, those values have already been computed, and are already on the table. Thus, we'll be able to compute the final result all the way up to <span class="math inline">\(w\)</span>, which is what we wanted.</p>
<p>Now, as for the base case, you could just directly count the sequences for, say, <span class="math inline">\(w&#39; = n\)</span>, since the winning sequence is basically the <em>sorted</em> version of the sequence itself. Alternatively, we can use <span class="math inline">\(w&#39; = 0\)</span> as our base case, though we need to think about what the winning sequence of a sequence with less than <span class="math inline">\(n\)</span> elements should be. Well, it makes sense to say that the winning sequence must be the whole sequence as well, just sorted. And instead of a <em>pushpop</em> operation, we could simply use a <em>push</em> operation, at least while the sequence still has length less than <span class="math inline">\(n\)</span>.</p>
<p>With this, we now have a solution! What's the running time? Well, the table has an entry for each <span class="math inline">\((W, w&#39;)\)</span> with <span class="math inline">\(W\)</span> a winner sequence and <span class="math inline">\(w&#39; \le w\)</span>. Recall that there are <span class="math inline">\(\binom{n + k - 1}{n}\)</span> winner sequences, so there are <span class="math inline">\(\approx \binom{n + k - 1}{n}w\)</span> entries. Each entry is computed with the sum above, which clearly has at most <span class="math inline">\(\binom{n + k - 1}{n}k\)</span> summands (often much less). Therefore, the amount of steps is roughly proportional to <span class="math display">\[\approx \binom{n + k - 1}{n}w\cdot \binom{n + k - 1}{n}k = \binom{n + k - 1}{n}^2 wk.\]</span> For Subtask 1, this is good enough; my straightforward Python implementation computes the <em>full</em> answer in less than one second.</p>
<div class="caution">
<p><strong>Note:</strong> Understanding this implementation is <em>not</em> required to understand the following sections, so you may skip it.</p>
</div>
<p><details class="code"><summary class="h4">Code (Python)</summary></p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> fractions <span class="im">import</span> Fraction <span class="im">as</span> Frac
<span class="im">from</span> functools <span class="im">import</span> cache
<span class="im">from</span> itertools <span class="im">import</span> combinations_with_replacement
<span class="im">from</span> math <span class="im">import</span> comb

<span class="kw">def</span> solve(n, w, k):
    <span class="at">@cache</span>
    <span class="kw">def</span> pushpop(W, v):
        <span class="cf">return</span> <span class="bu">tuple</span>(<span class="bu">sorted</span>([<span class="op">*</span>W, v])[<span class="op">-</span>n:])

    <span class="at">@cache</span>
    <span class="kw">def</span> winner_sequences(n):
        <span class="cf">return</span> <span class="bu">tuple</span>(combinations_with_replacement(<span class="bu">range</span>(<span class="dv">1</span>, k<span class="op">+</span><span class="dv">1</span>), n))

    <span class="cf">assert</span> <span class="bu">len</span>(winner_sequences(n)) <span class="op">==</span> comb(n <span class="op">+</span> k <span class="op">-</span> <span class="dv">1</span>, n)  <span class="co"># sanity check</span>

    <span class="at">@cache</span>
    <span class="kw">def</span> c(W, w):
        <span class="cf">assert</span> <span class="bu">len</span>(W) <span class="op">==</span> <span class="bu">min</span>(w, n)  <span class="co"># sanity check</span>

        <span class="cf">if</span> w <span class="op">==</span> <span class="dv">0</span>:
            <span class="cf">return</span> <span class="dv">1</span>
        <span class="cf">else</span>:
            <span class="cf">return</span> <span class="bu">sum</span>(c(WW, w <span class="op">-</span> <span class="dv">1</span>)
                <span class="cf">for</span> WW <span class="kw">in</span> winner_sequences(<span class="bu">min</span>(w <span class="op">-</span> <span class="dv">1</span>, n))
                <span class="cf">for</span> v <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, k<span class="op">+</span><span class="dv">1</span>)
                <span class="cf">if</span> pushpop(WW, v) <span class="op">==</span> W
            )

    <span class="kw">def</span> c_(t):
        <span class="cf">return</span> <span class="bu">sum</span>(c(W, w) <span class="cf">for</span> W <span class="kw">in</span> winner_sequences(n) <span class="cf">if</span> <span class="bu">sum</span>(W) <span class="op">==</span> t)

    <span class="kw">def</span> p_(t):
        <span class="cf">return</span> Frac(c_(t), k<span class="op">**</span>w)

    <span class="cf">return</span> <span class="bu">sum</span>(p_(t) <span class="op">*</span> t <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(n, n<span class="op">*</span>k <span class="op">+</span> <span class="dv">1</span>))</code></pre></div>
<p></details></p>
<div class="remarks">
<p><strong>Remark:</strong> The implementation tries to copy the mathematical formulas above as closely as possible. As a result, it's highly unoptimized, and there are definitely several improvements that be made. But the main point is that even such unoptimized code is enough to solve the subtask.</p>
</div>
<p></details></p>
<p><details class="editorial-section"><summary class="h2">Subtask 2</summary></p>
<h3 id="linearity-of-expectation">Linearity of expectation</h3>
<p>To find faster solutions, we use something called the “<strong>linearity of expectation</strong>”. Linearity of expectation means two things:</p>
<ul>
<li><span class="math inline">\(\operatorname{E}[\alpha X] = \alpha \operatorname{E}[X]\)</span> for any random variable <span class="math inline">\(X\)</span> and any constant <span class="math inline">\(\alpha\)</span>, and</li>
<li><span class="math inline">\(\operatorname{E}[X_1 + X_2] = \operatorname{E}[X_1] + \operatorname{E}[X_2]\)</span> for any two random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>.</li>
</ul>
<p>The first one is quite intuitive; after all, it's just scaling the values, so the <em>average</em> should just be scaled appropriately. However, the second property—additivity—may be surprising. The property could be intuitive in the case where <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are <em>independent</em>, but linearity doesn't <em>require</em> them to be—it's simply <em>always</em> true!</p>
<p>In a bonus section below, we'll explain why this is true, but for now, let's first try to apply this to the problem. Let <span class="math inline">\(T\)</span> be the same random variable as before, so it denotes the <em>sum</em> of the <span class="math inline">\(n\)</span> largest values of the sequence produced. Now, we define <span class="math inline">\(n\)</span> new random variables <span class="math inline">\(T_1, T_2, \ldots T_n\)</span>, where <span class="math inline">\(T_i\)</span> denotes the <span class="math inline">\(i\)</span>th largest value of the sequence. Then clearly we have <span class="math display">\[T = T_1 + T_2 + \ldots + T_n = \sum_{i=1}^n T_i.\]</span> Now, the <span class="math inline">\(T_i\)</span>'s are definitely not independent, e.g., knowing the largest value constrains the possible values of the second value, and vice versa. Regardless, <em>expectation is always additive</em>, so we have the equality <span class="math display">\[\operatorname{E}[T] = \operatorname{E}[T_1] + \operatorname{E}[T_2] + \ldots + \operatorname{E}[T_n] = \sum_{i=1}^n \operatorname{E}[T_i].\]</span> Thus, we've reduced the problem to computing <span class="math inline">\(\operatorname{E}[T_i]\)</span> for <span class="math inline">\(1 \le i \le n\)</span>, which is potentially more manageable!</p>
<h3 id="computing-operatornameet_i">Computing <span class="math inline">\(\operatorname{E}[T_i]\)</span></h3>
<p>Let's now try to compute <span class="math inline">\(\operatorname{E}[T_i]\)</span>, the expected value of the <span class="math inline">\(i\)</span>th largest element of the sequence. The possible values are between <span class="math inline">\(1\)</span> and <span class="math inline">\(k\)</span>, so by definition, we have <span class="math display">\[\operatorname{E}[T_i] = \sum_{v=1}^k \operatorname{P}[T_i = v]\cdot v,\]</span> where <span class="math inline">\(\operatorname{P}[T_i = v]\)</span> denotes the probability that <span class="math inline">\(T_i = v\)</span>. Next, we again turn probability into counting; noting that there are <span class="math inline">\(k^w\)</span> equally likely possibilities, we have something like <span class="math display">\[\operatorname{P}[T_i = v] = \frac{\mathit{count}_{=v}(i)}{k^w}\]</span> where <span class="math inline">\(\mathit{count}_{=v}(i)\)</span> denotes the number of sequences whose <span class="math inline">\(i\)</span>th largest value is <span class="math inline">\(v\)</span>. Thus, we're done if we can compute <span class="math inline">\(\mathit{count}_{=v}(i)\)</span>.</p>
<h3 id="computing-mathitcount_vi">Computing <span class="math inline">\(\mathit{count}_{=v}(i)\)</span></h3>
<p>We can compute <span class="math inline">\(\mathit{count}_{=v}(i)\)</span> by noting that:</p>
<div class="theorem">
<p><strong>Theorem 1:</strong> The <span class="math inline">\(i\)</span>th largest value of a sequence is <span class="math inline">\(v\)</span> if and only if</p>
<ul>
<li>the sequence has <span class="math inline">\(&lt; i\)</span> elements greater than <span class="math inline">\(v\)</span>, and</li>
<li>the sequence has <span class="math inline">\(\le w - i\)</span> elements less than <span class="math inline">\(v\)</span>.</li>
</ul>
</div>
<p>This is fairly intuitive, and you should try to prove it yourself 🙂. <details class="proof"><summary class="h4">Proof</summary> Sort the sequence in <strong>decreasing</strong> order, so the <span class="math inline">\(i\)</span>th element denotes the <span class="math inline">\(i\)</span>th largest value.</p>
<p>(⇒) Now, suppose the <span class="math inline">\(i\)</span>th largest element is <span class="math inline">\(v\)</span>, i.e., the element at index <span class="math inline">\(i\)</span> is <span class="math inline">\(v\)</span>. Then because the sequence is decreasing,</p>
<ul>
<li>only indices <span class="math inline">\(1\)</span> to <span class="math inline">\(i - 1\)</span> can have a value greater than <span class="math inline">\(v\)</span>, and there are <span class="math inline">\(&lt; i\)</span> of them; and</li>
<li>only indices <span class="math inline">\(i + 1\)</span> to <span class="math inline">\(w\)</span> can have a value less than <span class="math inline">\(v\)</span>, and there are <span class="math inline">\(\le w - i\)</span> of them.</li>
</ul>
<p>(⇐) On the other hand,</p>
<ul>
<li>if the sequence has <span class="math inline">\(&lt; i\)</span> values greater than <span class="math inline">\(v\)</span>, then <span class="math inline">\(&gt; w - i\)</span> values must be at most <span class="math inline">\(v\)</span>. Since the sequence is decreasing, indices <span class="math inline">\(i\)</span> to <span class="math inline">\(w\)</span> must have values at most <span class="math inline">\(v\)</span>; and</li>
<li>if the sequence has <span class="math inline">\(\le w - i\)</span> values less than <span class="math inline">\(v\)</span>, then <span class="math inline">\(\ge i\)</span> values must be at least <span class="math inline">\(v\)</span>. Since the sequence is decreasing, indices <span class="math inline">\(1\)</span> to <span class="math inline">\(i\)</span> must have values at least <span class="math inline">\(v\)</span>.</li>
</ul>
<p>In particular, the value at index <span class="math inline">\(i\)</span> must be at most <span class="math inline">\(v\)</span> and at least <span class="math inline">\(v\)</span> at the same time, so it must be equal to <span class="math inline">\(v\)</span>, i.e., the <span class="math inline">\(i\)</span>th largest value is <span class="math inline">\(v\)</span>. </details></p>
<p>Thus, we want to count the number of sequences with <span class="math inline">\(&lt; i\)</span> elements greater than <span class="math inline">\(v\)</span> and <span class="math inline">\(\le w - i\)</span> elements less than <span class="math inline">\(v\)</span>. Let</p>
<ul>
<li><span class="math inline">\(\ell\)</span> be the number of elements <span class="math inline">\(&lt; v\)</span>, and</li>
<li><span class="math inline">\(g\)</span> be the number of elements <span class="math inline">\(&gt; v\)</span>,</li>
</ul>
<p>so that <span class="math inline">\(\ell \le w - i\)</span> and <span class="math inline">\(g &lt; i\)</span>. Then using Theorem 1, we have the equality <span class="math display">\[\mathit{count}_{=v}(i) = \sum_{\ell=0}^{w-i} \sum_{g=0}^{i-1} c(\ell, g, v)\]</span> where <span class="math inline">\(c(\ell, g, v)\)</span> is the number of sequences with exactly <span class="math inline">\(\ell\)</span> elements <span class="math inline">\(&lt; v\)</span> and exactly <span class="math inline">\(g\)</span> elements <span class="math inline">\(&gt; v\)</span>. Finally, counting <span class="math inline">\(c(\ell, g, v)\)</span> is easy, because to build such a sequence, we could use the following process:</p>
<ol style="list-style-type: decimal">
<li>Among the <span class="math inline">\(w\)</span> indices, we first choose which <span class="math inline">\(\ell\)</span> elements will be <span class="math inline">\(&lt; v\)</span>. There are <span class="math inline">\(\binom{w}{\ell}\)</span> ways to do this.</li>
<li>Next, among the <span class="math inline">\(w - \ell\)</span> remaining indices, we choose which <span class="math inline">\(g\)</span> elements will be <span class="math inline">\(&gt; v\)</span>. There are <span class="math inline">\(\binom{w - \ell}{g}\)</span> ways to do this, and the remaining <span class="math inline">\(w - \ell - g\)</span> indices must contain the value <span class="math inline">\(v\)</span>.</li>
<li>Next, we choose the actual values of the elements <span class="math inline">\(&lt; v\)</span>. There are <span class="math inline">\(\ell\)</span> values to choose, and each one is an independent choice of a number between <span class="math inline">\(1\)</span> and <span class="math inline">\(v-1\)</span>, so there are <span class="math inline">\((v-1)^{\ell}\)</span> ways to do this.</li>
<li>Finally, we choose the actual values of the elements <span class="math inline">\(&gt; v\)</span>. There are <span class="math inline">\(g\)</span> values to choose, and each one is an independent choice of a number between <span class="math inline">\(v+1\)</span> and <span class="math inline">\(k\)</span>, so there are <span class="math inline">\((k-v)^g\)</span> ways to do this.</li>
</ol>
<p>Thus, all in all, there are <span class="math display">\[c(\ell, g, v) = \binom{w}{\ell} \cdot \binom{w - \ell}{g} \cdot (v-1)^{\ell} \cdot (k-v)^g\]</span> such sequences.</p>
<p>We now have a complete solution! How fast does it run? Well, we need to compute <span class="math inline">\(\operatorname{E}[T_i]\)</span> for <span class="math inline">\(1 \le i \le n\)</span>, which in turn require the values <span class="math inline">\(\mathit{count}_{=v}(i)\)</span> for <span class="math inline">\(1 \le i \le n\)</span> and <span class="math inline">\(1 \le v \le k\)</span>, which in turn require the values <span class="math inline">\(c(\ell, g, v)\)</span> for <span class="math inline">\(0 \le \ell \le w - 1\)</span>, <span class="math inline">\(0 \le g \le n - 1\)</span> and <span class="math inline">\(1 \le v \le k\)</span>.</p>
<ul>
<li><p>Each <span class="math inline">\(c(\ell, g, v)\)</span> value is a product of some binomial coefficients and powers. The powers can all be computed with fast exponentiation, or they could just be precomputed in a table at the beginning (since all powers we need have bases less than <span class="math inline">\(k\)</span>, and exponents less than <span class="math inline">\(w\)</span>), and the binomial coefficients can also be precomputed in a table, either via Pascal's identity, or precomputing factorials and using <span class="math display">\[\binom{a}{b} = \frac{a!}{(a - b)!b!}.\]</span> Therefore, we could say that each <span class="math inline">\(c(\ell, g, v)\)</span> can be computed in a constant amount of steps, and since there are <span class="math inline">\(\approx wnk\)</span> of them, the total number of steps to compute them all is <span class="math inline">\(\approx wnk\)</span>.</p></li>
<li><p>To compute the <span class="math inline">\(\mathit{count}_{=v}(i)\)</span> values, note that there are <span class="math inline">\(kn\)</span> such values, and each one is computed with a summation with <span class="math inline">\(\approx wn\)</span> summands. Therefore, it takes <span class="math inline">\(\approx wn^2 k\)</span> steps to compute them all.</p></li>
<li><p>The formula for <span class="math inline">\(\operatorname{E}[T]\)</span> has <span class="math inline">\(n\)</span> summands, each of which has a formula with <span class="math inline">\(k\)</span> summands, so this takes <span class="math inline">\(\approx nk\)</span> steps.</p></li>
<li><p>Finally, we also need to account for the precomputation of factorials and powers. There are <span class="math inline">\(\approx w\)</span> factorials and <span class="math inline">\(\approx kw\)</span> powers to precompute, so their precomputation takes <span class="math inline">\(\approx kw\)</span> steps.</p></li>
</ul>
<p>Thus, the running time is dominated by the computation of <span class="math inline">\(\mathit{count}_{=v}(i)\)</span>. For Subtask 2, we have <span class="math inline">\(wn^2 k = 6\cdot 10^9\)</span>, so the number of steps seems small enough for this to be waitable if you use a fast language and a highly optimized implementation. It may be slow though, so instead of that, let's just improve our algorithm further.</p>
<h3 id="computing-mathitcount_vi-more-quickly">Computing <span class="math inline">\(\mathit{count}_{=v}(i)\)</span> more quickly</h3>
<p>Let's look at <span class="math inline">\(\mathit{count}_{=v}(i)\)</span> again. It denotes the number of sequences whose <span class="math inline">\(i\)</span>th largest value is exactly <span class="math inline">\(v\)</span>. It turns out that it's easier to count the number of sequences whose <span class="math inline">\(i\)</span>th largest value is <strong>at most <span class="math inline">\(v\)</span></strong>. Even more nicely, it turns out that you can use the latter to compute the former!</p>
To see this, let's define <span class="math inline">\(\mathit{count}_{\le v}(i)\)</span> to be the number of sequences whose <span class="math inline">\(i\)</span>th largest value is at most <span class="math inline">\(v\)</span>. Then we easily have:
<div class="theorem">
<p><strong>Claim:</strong> <span class="math inline">\(\mathit{count}_{=v}(i) = \mathit{count}_{\le v}(i) - \mathit{count}_{\le v - 1}(i)\)</span>.</p>
</div>
<div class="proof">
<p><strong>Proof:</strong> Left as an exercise to the reader.</p>
</div>
So we've reduced the problem to computing <span class="math inline">\(\mathit{count}_{\le v}(i)\)</span> for <span class="math inline">\(0 \le v \le k\)</span> and <span class="math inline">\(1 \le i \le n\)</span>. So what? Well, here's what. It turns out that we can find a version of Theorem 1 that applies to <span class="math inline">\(\mathit{count}_{\le v}(i)\)</span>:
<div class="theorem">
<p><strong>Theorem 2:</strong> The <span class="math inline">\(i\)</span>th largest value of a sequence is at most <span class="math inline">\(v\)</span> if and only if the sequence has <span class="math inline">\(&lt; i\)</span> elements greater than <span class="math inline">\(v\)</span>.</p>
</div>
<div class="proof">
<p><strong>Proof:</strong> Left as an exercise to the reader.</p>
</div>
<p>And as you may notice, Theorem 2 is much simpler than Theorem 1!</p>
<p>We can now use a similar counting argument as before. Let <span class="math inline">\(g\)</span> be the number of elements greater than <span class="math inline">\(v\)</span>, so that <span class="math inline">\(g &lt; i\)</span>, and we can again write <span class="math display">\[\mathit{count}_{\le v}(i) = \sum_{g=0}^{i-1} c(g, v)\]</span> where now, <span class="math inline">\(c(g, v)\)</span> denotes the number of sequences with <em>exactly</em> <span class="math inline">\(g\)</span> elements greater than <span class="math inline">\(v\)</span>. Then we can count <span class="math inline">\(c(g, v)\)</span> similarly as before, except it's even simpler:</p>
<ol style="list-style-type: decimal">
<li>First, choose the <span class="math inline">\(g\)</span> indices that will be <span class="math inline">\(&gt; v\)</span>. There are <span class="math inline">\(\binom{w}{g}\)</span> ways to do this. The rest of the elements will be <span class="math inline">\(\le v\)</span>.</li>
<li>Then, we choose the actual values of the elements <span class="math inline">\(&gt; v\)</span>. There are <span class="math inline">\(g\)</span> values to choose, and each one is an independent choice of a number between <span class="math inline">\(v+1\)</span> and <span class="math inline">\(k\)</span>, so there are <span class="math inline">\((k-v)^g\)</span> ways to do this.</li>
<li>Finally, we choose the actual values of the elements <span class="math inline">\(\le v\)</span>. There are <span class="math inline">\(w - g\)</span> values to choose, and each one is an independent choice of a number between <span class="math inline">\(1\)</span> and <span class="math inline">\(v\)</span>, so there are <span class="math inline">\(v^{w - g}\)</span> ways to do this.</li>
</ol>
<p>Therefore, we have the simpler formula <span class="math display">\[c(g, v) = \binom{w}{g}\cdot (k - v)^g \cdot v^{w - g}.\]</span></p>
<p>We can now estimate the new running time. We now expect it to be better since the formulas are now simpler, and in particular, the double nested summations have become single summations. In fact, if we perform the same estimation, we find that the number of steps is <span class="math inline">\(\approx wk + n^2 k\)</span>, which is now definitely fast enough for Subtask 2!</p>
<div class="task">
<p><strong>Bonus:</strong> We can similarly define <span class="math inline">\(\mathit{count}_{\ge v}(i)\)</span> and write <span class="math display">\[\mathit{count}_{= v}(i) = \mathit{count}_{\ge v}(i) - \mathit{count}_{\ge v + 1}(i).\]</span> What happens to the running time when you base your algorithm on this?</p>
</div>
<p></details></p>
<p><details class="editorial-section"><summary class="h2">Subtask 3</summary></p>
<p>The main change from Subtask 2 to Subtask 3 is that <span class="math inline">\(w\)</span> is vastly increased, which means the portion of our previous algorithm that takes <span class="math inline">\(\approx wk\)</span> steps is now unacceptable. Let's recap what those steps are:</p>
<ol style="list-style-type: decimal">
<li>precomputing factorials up to <span class="math inline">\(w\)</span>, and</li>
<li>precomputing powers up to base <span class="math inline">\(k\)</span> and up to exponent <span class="math inline">\(w\)</span>.</li>
</ol>
<p>Among these, the second one clearly dominates the running time. But we can essentially get rid of the second one by simply <em>not</em> precomputing powers, and instead just fast exponentiation to compute them when needed! This makes the running time slightly worse—fast exponentiation takes <span class="math inline">\(\mathcal{O}(\lg w)\)</span> steps for an exponent the size of <span class="math inline">\(w\)</span>—but that's a very worthwhile tradeoff, because you can check that the number of steps improves from <span class="math inline">\(\mathcal{O}(wk + n^2 k)\)</span> to <span class="math display">\[\mathcal{O}(w + n^2 k + nk \lg w).\]</span> This is now acceptable for Subtask 3 🙂.</p>
<p>Now, there's still that factor <span class="math inline">\(w\)</span> in the running time, which in the current subtask is probably ok since <span class="math inline">\(w = 10^8\)</span>. However, in later subtasks, <span class="math inline">\(w = 10^{16}\)</span>, which suggests that that bit can still be improved further.</p>
<p>How can we improve it? Well, the main reason for needing factorials up to <span class="math inline">\(w\)</span> is so that we can compute binomial coefficients. But looking closer, notice that we actually only need binomial coefficients <strong>at exactly row <span class="math inline">\(w\)</span></strong>. Furthermore, we actually only need the first <span class="math inline">\(n\)</span> coefficients in it. And as it turns out, there's a way to compute a row of binomial coefficients one by one, starting from the leftmost one, by using the following recurrence (which is easy to prove using the factorial formula): <span class="math display">\[\binom{w}{g} = \binom{w}{g - 1}\cdot \frac{w - g + 1}{g},\]</span> with base case simply <span class="math inline">\(\binom{w}{0} = 1\)</span>. So now, instead of precomputing factorials, we may simply precompute the needed binomial coefficients using this recurrence with just <span class="math inline">\(\approx n\)</span> steps! The running time then improves to <span class="math display">\[\mathcal{O}(n^2 k + nk \log w),\]</span> which is really cool.</p>
<p></details></p>
<p><details class="editorial-section"><summary class="h2">Subtasks 4 &amp; 5</summary></p>
<p>Our previous algorithm is now too slow; in particular, that <span class="math inline">\(\mathcal{O}(n^2 k)\)</span> bit in the running time is now too large. For the rest of the subtasks, I'll just give a couple of hints to guide you towards faster solutions.</p>
<p><details class="task"><summary class="h4">Hint 1</summary> Do you really have to compute the whole sum <span class="math display">\[\mathit{count}_{\le v}(i) = \sum_{g=0}^{i-1} c(g, v)\]</span> every time? </details></p>
<p><details class="task"><summary class="h4">Hint 2</summary> Notice that <span class="math display">\[(k - v)^g\cdot v^{w - g} = v^w \cdot \left(\frac{k - v}{v}\right)^g.\]</span> Letting <span class="math inline">\(x_v := \frac{k - v}{v}\)</span>, this is the same as <span class="math inline">\(v^w x_v^g\)</span>. </details></p>
<p></details></p>
<p><details class="editorial-section"><summary class="h2">Bonus: Linearity of expectation</summary></p>
<p>This section is devoted to explaining why expectation is <em>linear</em>. Recall from above that linearity means two properties:</p>
<ul>
<li><strong>Scaling:</strong> <span class="math inline">\(\operatorname{E}[\alpha X] = \alpha \operatorname{E}[X]\)</span> for any random variable <span class="math inline">\(X\)</span> and any constant <span class="math inline">\(\alpha\)</span>, and</li>
<li><strong>Additivity:</strong> <span class="math inline">\(\operatorname{E}[X_1 + X_2] = \operatorname{E}[X_1] + \operatorname{E}[X_2]\)</span> for any two random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>.</li>
</ul>
<p>The first one is simple enough, and you should be able to prove it yourself 🙂. The real surprise is the second, which holds even if <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are not independent. (For independent variables, this may not be a surprise, since “clearly” the variables have nothing to do with each other,<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> so the averages should “just add up.”)</p>
<p>Let's see an example of this, using our current problem itself, with <span class="math inline">\(n = 2\)</span>, <span class="math inline">\(w = 3\)</span> and <span class="math inline">\(k = 2\)</span>. In this case, we have <span class="math display">\[T = T_1 + T_2\]</span> where <span class="math inline">\(T_i\)</span> is the value of the <span class="math inline">\(i\)</span>th largest element. Clearly, <span class="math inline">\(T_1\)</span> and <span class="math inline">\(T_2\)</span> are not independent; for example, we know that <span class="math inline">\(T_1\)</span> is at least <span class="math inline">\(T_2\)</span>, so if <span class="math inline">\(T_2\)</span> is <span class="math inline">\(2\)</span>, then <span class="math inline">\(T_1\)</span> must be <span class="math inline">\(2\)</span> as well.</p>
<p>Regardless, we will now illustrate that <span class="math display">\[\operatorname{E}[T] = \operatorname{E}[T_1] + \operatorname{E}[T_2]\]</span> by simply enumerating all <span class="math inline">\(2^3 = 8\)</span> possible sequences:</p>
<ul>
<li>For <span class="math inline">\([1, 1, 1]\)</span>, we have <span class="math inline">\(T_1 = 1\)</span>, <span class="math inline">\(T_2 = 1\)</span> and <span class="math inline">\(T = 2\)</span>;</li>
<li>For <span class="math inline">\([1, 1, 2]\)</span>, we have <span class="math inline">\(T_1 = 2\)</span>, <span class="math inline">\(T_2 = 1\)</span> and <span class="math inline">\(T = 3\)</span>;</li>
<li>For <span class="math inline">\([1, 2, 1]\)</span>, we have <span class="math inline">\(T_1 = 2\)</span>, <span class="math inline">\(T_2 = 1\)</span> and <span class="math inline">\(T = 3\)</span>;</li>
<li>For <span class="math inline">\([1, 2, 2]\)</span>, we have <span class="math inline">\(T_1 = 2\)</span>, <span class="math inline">\(T_2 = 2\)</span> and <span class="math inline">\(T = 4\)</span>;</li>
<li>For <span class="math inline">\([2, 1, 1]\)</span>, we have <span class="math inline">\(T_1 = 2\)</span>, <span class="math inline">\(T_2 = 1\)</span> and <span class="math inline">\(T = 3\)</span>;</li>
<li>For <span class="math inline">\([2, 1, 2]\)</span>, we have <span class="math inline">\(T_1 = 2\)</span>, <span class="math inline">\(T_2 = 2\)</span> and <span class="math inline">\(T = 4\)</span>;</li>
<li>For <span class="math inline">\([2, 2, 1]\)</span>, we have <span class="math inline">\(T_1 = 2\)</span>, <span class="math inline">\(T_2 = 2\)</span> and <span class="math inline">\(T = 4\)</span>;</li>
<li>For <span class="math inline">\([2, 2, 2]\)</span>, we have <span class="math inline">\(T_1 = 2\)</span>, <span class="math inline">\(T_2 = 2\)</span> and <span class="math inline">\(T = 4\)</span>.</li>
</ul>
<p>We can now compute the averages as follows: <span class="math display">\[\begin{align*}
\operatorname{E}[T_1] &amp;= \frac{1 + 2 + 2 + 2 + 2 + 2 + 2 + 2}{8} = 1.875;\\
\operatorname{E}[T_2] &amp;= \frac{1 + 1 + 1 + 2 + 1 + 2 + 2 + 2}{8} = 1.5;\\
\operatorname{E}[T]   &amp;= \frac{2 + 3 + 3 + 4 + 3 + 4 + 4 + 4}{8} = 3.375,
\end{align*}\]</span> and sure enough, <span class="math inline">\(3.375 = 1.875 + 1.5\)</span>, even though <span class="math inline">\(T_1\)</span> and <span class="math inline">\(T_2\)</span> are not independent.</p>
<p>But actually, this little calculation illustrates pretty well <em>why</em> expectation is additive; we're simply adding the same things in different ways! To illustrate this further, we can tabulate everything as follows: <span class="math display">\[\begin{array}{l|l|lll}
s &amp; p_s &amp; T_1 &amp; T_2 &amp; T \\
\hline
[1, 1, 1] &amp; \frac{1}{8} &amp; 1 &amp; 1 &amp; 2 \\
[1, 1, 2] &amp; \frac{1}{8} &amp; 2 &amp; 1 &amp; 3 \\
[1, 2, 1] &amp; \frac{1}{8} &amp; 2 &amp; 1 &amp; 3 \\
[1, 2, 2] &amp; \frac{1}{8} &amp; 2 &amp; 2 &amp; 4 \\
[2, 1, 1] &amp; \frac{1}{8} &amp; 2 &amp; 1 &amp; 3 \\
[2, 1, 2] &amp; \frac{1}{8} &amp; 2 &amp; 2 &amp; 4 \\
[2, 2, 1] &amp; \frac{1}{8} &amp; 2 &amp; 2 &amp; 4 \\
[2, 2, 2] &amp; \frac{1}{8} &amp; 2 &amp; 2 &amp; 4.
\end{array}\]</span> Now, the <span class="math inline">\(T\)</span> column is clearly the sum of the <span class="math inline">\(T_1\)</span> and <span class="math inline">\(T_2\)</span> columns. We can now <em>distribute</em> the probabilities in each row: <span class="math display">\[\begin{array}{l|lll}
s &amp; p_sT_1 &amp; p_sT_2 &amp; p_sT \\
\hline
[1, 1, 1] &amp; \frac{1}{8} &amp; \frac{1}{8} &amp; \frac{2}{8} \\
[1, 1, 2] &amp; \frac{2}{8} &amp; \frac{1}{8} &amp; \frac{3}{8} \\
[1, 2, 1] &amp; \frac{2}{8} &amp; \frac{1}{8} &amp; \frac{3}{8} \\
[1, 2, 2] &amp; \frac{2}{8} &amp; \frac{2}{8} &amp; \frac{4}{8} \\
[2, 1, 1] &amp; \frac{2}{8} &amp; \frac{1}{8} &amp; \frac{3}{8} \\
[2, 1, 2] &amp; \frac{2}{8} &amp; \frac{2}{8} &amp; \frac{4}{8} \\
[2, 2, 1] &amp; \frac{2}{8} &amp; \frac{2}{8} &amp; \frac{4}{8} \\
[2, 2, 2] &amp; \frac{2}{8} &amp; \frac{2}{8} &amp; \frac{4}{8}.
\end{array}\]</span> and note that the <span class="math inline">\(p_sT\)</span> column is still the sum of the <span class="math inline">\(p_sT_1\)</span> and <span class="math inline">\(p_sT_2\)</span> columns. Finally, computing <span class="math inline">\(\operatorname{E}[T]\)</span> amounts to taking the <em>sum</em> of the <span class="math inline">\(p_sT\)</span> column, while computing <span class="math inline">\(\operatorname{E}[T_1] + \operatorname{E}[T_2]\)</span> amounts to taking the sum of the <span class="math inline">\(p_sT_1\)</span> and <span class="math inline">\(p_sT_2\)</span> columns separately, then adding them. But these are clearly the same! (And this worked even if <span class="math inline">\(T_1\)</span> and <span class="math inline">\(T_2\)</span> aren't independent.)</p>
<p>It should now not be too hard to formalize this argument and make it more general. If you're interested, here it is: <details class="proof"><summary class="h4">Proof</summary></p>
<p>Suppose the sample space <span class="math inline">\(k\)</span> elements <span class="math display">\[\{\omega_1, \omega_2, \ldots, \omega_k\}\]</span> with respective probabilities <span class="math inline">\(p_1, p_2, \ldots, p_k\)</span>. Next, for each <span class="math inline">\(i\)</span>, define <span class="math inline">\(t_i\)</span>, <span class="math inline">\(u_i\)</span>, and <span class="math inline">\(v_i\)</span> as the values that <span class="math inline">\(T\)</span>, <span class="math inline">\(T_1\)</span> and <span class="math inline">\(T_2\)</span> take at the element <span class="math inline">\(\omega_i\)</span> of the sample space, i.e., for each <span class="math inline">\(i\)</span>: <span class="math display">\[\begin{align*}
T(\omega_i) &amp;= t_i \\
T_1(\omega_i) &amp;= u_i \\
T_2(\omega_i) &amp;= v_i.
\end{align*}\]</span> Since <span class="math inline">\(T = T_1 + T_2\)</span>, we must always have <span class="math inline">\(t_i = u_i + v_i\)</span>. Then by the <a href="https://en.wikipedia.org/wiki/Law_of_the_unconscious_statistician">law of the unconscious statistician</a>, <span class="math display">\[\begin{align*}
\operatorname{E}[T]
&amp;= \sum_{i=1}^k p_i \cdot T(\omega_i) \\
&amp;= \sum_{i=1}^k p_i \cdot t_i \\
&amp;= \sum_{i=1}^k p_i \cdot (u_i + v_i) \\
&amp;= \sum_{i=1}^k p_i \cdot u_i + \sum_{i=1}^k p_i \cdot v_i \\
&amp;= \sum_{i=1}^k p_i \cdot T_1(\omega_i) + \sum_{i=1}^k p_i \cdot T_2(\omega_i) \\
&amp;= \operatorname{E}[T_1] + \operatorname{E}[T_2].
\end{align*}\]</span> </details></p>
Just as practice, you could try proving the <em>scaling</em> property formally yourself:
<div class="task">
<p><strong>Exercise:</strong> Prove the <em>scaling</em> property of expectation formally.</p>
</div>
<p></details></p>
<p><details class="editorial-section"><summary class="h2">Bonus: Computing rational numbers modulo <span class="math inline">\(998244353\)</span></summary></p>
<p>All solutions we described above compute the <em>full</em> answer, i.e., we pretend we were working on <span class="math inline">\(\mathbb{R}\)</span> where we can add, subtract, multiply, and crucially, divide, numbers. Actually, we could also pretend we are working on <span class="math inline">\(\mathbb{Q}\)</span>, i.e., the rationals, since all intermediate results are clearly rational, and we can also do the same arithmetic operations there.</p>
<p>Now, in many problems, we can usually convert such full-answer solutions into solutions that compute the answer mod <span class="math inline">\(m\)</span>, say <span class="math inline">\(m = 998244353\)</span>, because we can also add, subtract and multiply numbers mod <span class="math inline">\(m\)</span>. However, division mod <span class="math inline">\(m\)</span> is more complicated; it sometimes doesn't work at all. To see this, let <span class="math inline">\(m = 10\)</span>, and note that <span class="math inline">\(12 \equiv 32 \pmod{10}\)</span>, but dividing by <span class="math inline">\(4\)</span> fails: <span class="math display">\[\frac{12}{4} = 3 \not\equiv 8 = \frac{32}{4} \pmod{10}.\]</span></p>
<h3 id="computing-ab-bmod-m-by-trial-and-error">Computing <span class="math inline">\(a/b \bmod m\)</span> by trial and error</h3>
<p>Before we tackle this issue, let's first see if we can compute <span class="math inline">\(a/b \bmod m\)</span> based solely on the definition given in the problem statement. Suppose you've computed the full answer as <span class="math inline">\(a/b\)</span>, and let's say it's in lowest terms. Then the problem guarantees us that <span class="math inline">\(a/b \bmod m\)</span> is well-defined, and it is the unique number <span class="math inline">\(q\)</span> such that “<span class="math inline">\(a/b - q = \frac{a - qb}{b}\)</span> is divisible by <span class="math inline">\(m\)</span>”, which by definition means that <span class="math inline">\(\frac{a - qb}{b}\)</span> can be written as a fraction whose numerator is divisible by <span class="math inline">\(m\)</span> but whose denominator is not. Now, the fraction <span class="math inline">\(\frac{a - qb}{b}\)</span> is already in lowest terms (why?), so this means two things:</p>
<ul>
<li><span class="math inline">\(b\)</span> must not be divisible by <span class="math inline">\(m\)</span> (which we can check), otherwise there's no hope of <span class="math inline">\(\frac{a - qb}{b}\)</span> being divisible by <span class="math inline">\(m\)</span>.</li>
<li><span class="math inline">\(a - qb\)</span> is divisible by <span class="math inline">\(m\)</span>. To find such a <span class="math inline">\(q\)</span>, we could simply use brute force: check each <span class="math inline">\(q\)</span> from <span class="math inline">\(0\)</span> to <span class="math inline">\(m-1\)</span> and find one where <span class="math inline">\(a - qb\)</span> is divisible by <span class="math inline">\(m\)</span>. The problem statement says that such a <span class="math inline">\(q\)</span> is unique.</li>
</ul>
<p>All in all, this takes <span class="math inline">\(\approx m\)</span> steps in the worst case to find <span class="math inline">\(q\)</span>, which is the answer we're looking for. With <span class="math inline">\(m = 998244353 \approx 10^9\)</span>, that isn't so bad, especially if <span class="math inline">\(a/b\)</span> doesn't have too many digits. So for Subtasks 1 and 2, that's more-or-less okay. But for the larger subtasks the numbers become too large<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> which makes it not okay, and we clearly need to do something else.</p>
<h3 id="working-modulo-m">Working “modulo <span class="math inline">\(m\)</span>”</h3>
<p>You might suspect that the reason that dividing by <span class="math inline">\(4\)</span> failed modulo <span class="math inline">\(10\)</span> is that <span class="math inline">\(4\)</span> and <span class="math inline">\(10\)</span> share a common factor. And indeed, that's a good hunch. For example, dividing by <span class="math inline">\(3\)</span> seems to work modulo <span class="math inline">\(10\)</span>, which you can check with lots of small examples, or maybe by using a program to do several checks for you, e.g.: <details class="code"><summary class="h4">Code (Python)</summary></p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> math <span class="im">import</span> gcd

<span class="kw">def</span> congruent(m, a, b):
    <span class="co">&quot;&quot;&quot; a == b (mod m) &quot;&quot;&quot;</span>
    <span class="cf">return</span> (a <span class="op">-</span> b) <span class="op">%</span> m <span class="op">==</span> <span class="dv">0</span>

m <span class="op">=</span> <span class="dv">10</span>

<span class="co"># try denominators coprime with m</span>
denominators <span class="op">=</span> [d <span class="cf">for</span> d <span class="kw">in</span> <span class="bu">range</span>(<span class="op">-</span><span class="dv">100</span>, <span class="dv">100</span><span class="op">+</span><span class="dv">1</span>) <span class="cf">if</span> gcd(m, d) <span class="op">==</span> <span class="dv">1</span>]

<span class="cf">for</span> den <span class="kw">in</span> denominators:
    <span class="bu">print</span>(<span class="st">&quot;Checking&quot;</span>, den)

    <span class="co"># take several numbers divisible by den</span>
    nums <span class="op">=</span> [den <span class="op">*</span> v <span class="cf">for</span> v <span class="kw">in</span> <span class="bu">range</span>(<span class="op">-</span><span class="dv">1000</span>, <span class="dv">1000</span><span class="op">+</span><span class="dv">1</span>)]

    <span class="cf">for</span> num1 <span class="kw">in</span> nums:
        <span class="cf">for</span> num2 <span class="kw">in</span> nums:
            <span class="co"># check that if num1 == num2 then (num1/den) == (num2/den), mod m</span>
            <span class="cf">if</span> congruent(m, num1, num2):
                <span class="cf">assert</span> congruent(m, num1 <span class="op">//</span> den, num2 <span class="op">//</span> den)

<span class="bu">print</span>(<span class="st">&quot;All OK&quot;</span>)</code></pre></div>
<p></details> You can replace <code class="sourceCode python">m <span class="op">=</span> <span class="dv">10</span></code> with other numbers and it still seems to work! So clearly, there seems to be some sense in which division “kinda makes sense”, as long as the number you're dividing with is coprime with the modulus <span class="math inline">\(m\)</span>.</p>
<p>And as it turns out, we can prove that fact!</p>
<div class="theorem">
<p><strong>Theorem A:</strong> If <span class="math inline">\(da \equiv db \pmod{m}\)</span> and <span class="math inline">\(\gcd(m, d) = 1\)</span>, then <span class="math inline">\(a \equiv b \pmod{m}\)</span>.</p>
</div>
<div class="proof">
<p><strong>Proof:</strong> Fairly straightforward, so we leave it to the reader.</p>
</div>
<p>Now that's all well and good, but what we really want is to be able to <em>divide</em> modulo <span class="math inline">\(m\)</span>. For this, we should answer the following question first: <em>what is division, really</em>? Well, dividing is the same as multiplying by the <em>multiplicative inverse</em>, that is, <span class="math inline">\(a/b\)</span> is the same as <span class="math inline">\(ab^{-1}\)</span>, where <span class="math inline">\(b^{-1} = 1/b\)</span> is the multiplicative inverse of <span class="math inline">\(b\)</span>. But what is a multiplicative inverse? Well, <span class="math inline">\(b^{-1}\)</span> is defined as the unique number such that <span class="math inline">\(bb^{-1} = 1\)</span>.</p>
<p>Now, as it turns out, multiplicative inverses sometimes exist modulo <span class="math inline">\(m\)</span>. In the mod <span class="math inline">\(m\)</span> world, the multiplicative inverse of <span class="math inline">\(b\)</span> is still denoted <span class="math inline">\(b^{-1}\)</span>, but this time, it's not a fraction. Nonetheless, it's still defined analogously; <span class="math inline">\(b^{-1}\)</span> is the “unique” number such that <span class="math display">\[bb^{-1} \equiv 1 \pmod{m}.\]</span> Note that I put “unique” in quotes because if <span class="math inline">\(x\)</span> is a multiplicative inverse, then <span class="math inline">\(x + m\)</span> is also one, as is <span class="math inline">\(x + 2m\)</span>, <span class="math inline">\(x - m\)</span>, etc. But as it turns out, all these numbers are the same mod <span class="math inline">\(m\)</span>, which is what we mean by “unique“ here.</p>
We can actually prove that fact, and in fact, something stronger:
<div class="theorem">
<p><strong>Theorem B:</strong> <span class="math inline">\(b\)</span> has a multiplicative inverse if and only if <span class="math inline">\(b\)</span> and <span class="math inline">\(m\)</span> and coprime, and it is unique if it exists.</p>
</div>
<p><details class="proof"><summary class="h4">Proof</summary></p>
<p>(⇒) Suppose <span class="math inline">\(b\)</span> has a multiplicative inverse <span class="math inline">\(b&#39;\)</span>, so that <span class="math display">\[bb&#39; \equiv 1 \pmod{m}.\]</span> This is equivalent to saying that there's a <span class="math inline">\(k\)</span> such that <span class="math display">\[bb&#39; - mk = 1.\]</span> Now, if <span class="math inline">\(d\)</span> is a common divisor of <span class="math inline">\(b\)</span> and <span class="math inline">\(m\)</span>, then <span class="math inline">\(d\)</span> divides the left-hand side, so it must also divide the right-hand side, which is <span class="math inline">\(1\)</span>. Thus, all common divisors of <span class="math inline">\(b\)</span> and <span class="math inline">\(m\)</span> divide <span class="math inline">\(1\)</span>, which means they are coprime.</p>
<p>(⇐) Suppose <span class="math inline">\(b\)</span> and <span class="math inline">\(m\)</span> are coprime, so their gcd is <span class="math inline">\(1\)</span>. By <a href="https://en.wikipedia.org/wiki/B%C3%A9zout%27s_identity">Bézout's</a>, there are integers <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> such that <span class="math display">\[bx + my = 1.\]</span> Reducing this modulo <span class="math inline">\(m\)</span> gives <span class="math display">\[bx \equiv 1 \pmod{m},\]</span> so <span class="math inline">\(x\)</span> is a multiplicative inverse of <span class="math inline">\(b\)</span>.</p>
<p>(Uniqueness) Suppose <span class="math inline">\(b&#39;\)</span> and <span class="math inline">\(b&#39;&#39;\)</span> are both multiplicative inverses of <span class="math inline">\(b\)</span>. Then <span class="math display">\[\begin{align*}
    bb&#39; &amp;\equiv 1 \pmod{m} \\
    bb&#39;&#39; &amp;\equiv 1 \pmod{m},
\end{align*}\]</span> so <span class="math display">\[bb&#39; \equiv bb&#39;&#39; \pmod{m}.\]</span> But <span class="math inline">\(m\)</span> and <span class="math inline">\(b\)</span> are coprime (since a multiplicative inverse exists), so by using Theorem A, <span class="math inline">\(b&#39; \equiv b&#39;&#39; \pmod{m}\)</span>, so any two multiplicative inverses of <span class="math inline">\(b\)</span> are the same mod <span class="math inline">\(m\)</span>.</p>
<p></details></p>
<div class="remarks">
<p><strong>Remark:</strong> The proof can actually be turned into an algorithm to compute the multiplicative inverse, since the integers <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> guaranteed by Bézout's identity can be computed using the <strong>extended version of Euclid's gcd algorithm.</strong></p>
</div>
<p>So with this, we're now fairly able to “divide modulo <span class="math inline">\(m\)</span>”, as long as the divisors are coprime with <span class="math inline">\(m\)</span>. Since we're using the modulus <span class="math inline">\(m = 998244353\)</span> which is prime, most numbers are coprime! The only ones we can't divide with are those divisible by <span class="math inline">\(m\)</span> itself, but since such numbers are <span class="math inline">\(\equiv 0 \pmod{m}\)</span>, it makes sense not to be able to divide with them since that's sort of equivalent to dividing by <span class="math inline">\(0\)</span>.</p>
<p>Now, that's well and good, but we still need to relate this way of dividing modulo <span class="math inline">\(m\)</span> with the definition given in the statement. As it turns out, everything is okay; we can prove that <span class="math inline">\(a/b \bmod m\)</span>, as defined in the statement, is the same as <span class="math inline">\(ab^{-1} \bmod m\)</span>, using the following theorem:</p>
<div class="theorem">
<p><strong>Theorem C:</strong> For a rational <span class="math inline">\(r\)</span>, <span class="math inline">\(r \bmod m\)</span> exists if and only if <span class="math inline">\(r\)</span> can be written as <span class="math inline">\(a/b\)</span> with <span class="math inline">\(b\)</span> coprime with <span class="math inline">\(m\)</span>, and if it exists, then we have the equality <span class="math display">\[(a/b \bmod m) = (ab^{-1} \bmod m).\]</span></p>
</div>
<p>For this theorem to work, we will amend the definitions given in the statement as follows: We say a rational is <strong>divisible by <span class="math inline">\(m\)</span></strong> if it can be written as <span class="math inline">\(a/b\)</span> with <span class="math inline">\(a\)</span> divisible by <span class="math inline">\(m\)</span> and <span class="math inline">\(b\)</span> <em>coprime</em> with <span class="math inline">\(m\)</span>. This is equivalent to the definition in the statement when <span class="math inline">\(m\)</span> is prime, but is friendlier to nonprime moduli.</p>
<p><details class="proof"><summary class="h4">Proof</summary></p>
<p>(⇒) Suppose <span class="math inline">\(r \bmod m\)</span> exists, i.e., there's a unique <span class="math inline">\(q\)</span> such that <span class="math inline">\(r - q\)</span> is “divisible by <span class="math inline">\(m\)</span>” (as defined above). Writing <span class="math inline">\(r\)</span> in lowest terms as <span class="math inline">\(a/b\)</span>, we note that <span class="math inline">\(a/b - q = \frac{a - bq}{b}\)</span> is also in lowest terms.</p>
<p>By definition of divisibility, <span class="math inline">\(\frac{a - qb}{b}\)</span> can be written as <span class="math inline">\(a&#39;/b&#39;\)</span> with <span class="math inline">\(m\)</span> dividing <span class="math inline">\(a&#39;\)</span> but coprime with <span class="math inline">\(b&#39;\)</span>. Since <span class="math display">\[\frac{a - qb}{b} = \frac{a&#39;}{b&#39;}\]</span> and the former is in lowest terms, it follows that <span class="math inline">\(a - qb\)</span> is a divisor of <span class="math inline">\(a&#39;\)</span> and <span class="math inline">\(b\)</span> is a divisor of <span class="math inline">\(b&#39;\)</span>. But if <span class="math inline">\(m\)</span> and <span class="math inline">\(b&#39;\)</span> are coprime and <span class="math inline">\(b \mid b&#39;\)</span>, then <span class="math inline">\(m\)</span> and <span class="math inline">\(b\)</span> must be coprime as well.</p>
<p>(⇐) Suppose <span class="math inline">\(r = a/b\)</span> with <span class="math inline">\(b\)</span> is coprime with <span class="math inline">\(m\)</span>. Then I claim that <span class="math display">\[q := (ab^{-1} \bmod m)\]</span> satisfies the definition of <span class="math inline">\(r \bmod m\)</span>. Note that <span class="math display">\[r - q = \frac{a - qb}{b},\]</span> and we already know <span class="math inline">\(b\)</span> is coprime with <span class="math inline">\(m\)</span>, so it's sufficient to show that <span class="math inline">\(a - qb\)</span> is divisible by <span class="math inline">\(m\)</span>, i.e., <span class="math inline">\(a \equiv qb \pmod{m}\)</span>. That's shown as follows: <span class="math display">\[\begin{align*}
qb 
&amp;\equiv (ab^{-1})b \\
&amp;\equiv a(bb^{-1}) \\
&amp;\equiv a\cdot(1) \\
&amp;= a \pmod{m}.
\end{align*}\]</span></p>
<p>So <span class="math inline">\(r - q\)</span> is indeed divisible by <span class="math inline">\(m\)</span>. All that remains is to show that <span class="math inline">\(q\)</span> is the unique one satisfying the definition. If <span class="math inline">\(q&#39;\)</span> also satisfies the definition, then <span class="math inline">\(\frac{a - q&#39;b}{b}\)</span> is also divisible by <span class="math inline">\(m\)</span>, so we can write it as <span class="math display">\[\frac{a - q&#39;b}{b} = \frac{a&#39;}{b&#39;}\]</span> with <span class="math inline">\(m\)</span> dividing <span class="math inline">\(a&#39;\)</span> and coprime with <span class="math inline">\(b&#39;\)</span>. Rearranging this gives <span class="math display">\[(a - q&#39;b)b&#39; = a&#39;b.\]</span> Because <span class="math inline">\(m \mid a&#39;\)</span>, <span class="math inline">\(m\)</span> must divide the left-hand side <span class="math inline">\((a - q&#39;b)b&#39;\)</span> as well, but since <span class="math inline">\(m\)</span> and <span class="math inline">\(b&#39;\)</span> are coprime, <span class="math inline">\(m\)</span> must divide <span class="math inline">\(a - q&#39;b\)</span>, i.e., <span class="math display">\[a \equiv q&#39;b \pmod{m}.\]</span> Multiplying both sides by <span class="math inline">\(b^{-1}\)</span>, we get <span class="math display">\[q&#39; \equiv ab^{-1} \equiv q \pmod{m}.\]</span> In other words, any other possible value <span class="math inline">\(q&#39;\)</span> of <span class="math inline">\((r \bmod m)\)</span> must be equal to <span class="math inline">\(q = (ab^{-1} \bmod m)\)</span>, so it's unique. </details></p>
<div class="theorem">
<p><strong>Corollary:</strong> Suppose <span class="math inline">\(r\)</span> cannot be written as <span class="math inline">\(a/b\)</span> with <span class="math inline">\(b\)</span> coprime with <span class="math inline">\(m\)</span>. Then there is <em>no</em> integer <span class="math inline">\(q\)</span> such that <span class="math inline">\(r - q\)</span> is divisible by <span class="math inline">\(m\)</span>.</p>
</div>
<p>Note that this doesn't follow immediately from the definition, since if <span class="math inline">\(r \bmod m\)</span> doesn't exist, then all we can say from the definition is that there isn't <em>exactly one</em> <span class="math inline">\(q\)</span> such that <span class="math inline">\(r - q\)</span> is divisible by <span class="math inline">\(m\)</span>. In particular, there may be zero, or there may be more than one. This corollary rules out the latter.</p>
<p><details class="proof"><summary class="h4">Proof</summary></p>
<p>We prove the contrapositive.</p>
<p>Suppose there is a <span class="math inline">\(q\)</span> such that <span class="math inline">\(r - q\)</span> is divisible by <span class="math inline">\(m\)</span>. Notice that the “(⇒)” portion of the previous proof doesn't really use the fact that <span class="math inline">\(q\)</span> is unique, so the proof also goes through here just fine, and it proves that <span class="math inline">\(r\)</span> can be written as <span class="math inline">\(a/b\)</span> with <span class="math inline">\(b\)</span> coprime with <span class="math inline">\(m\)</span>. </details></p>
<p>With this, we can now completely work modulo <span class="math inline">\(m = 998244353\)</span> all throughout! All that we need now is to check that we're only ever dividing with numbers without <span class="math inline">\(m\)</span> as a prime factor. The possible divisors come from <span class="math inline">\(k^w\)</span> and the numbers coming from the computation of <span class="math inline">\(\binom{w}{g}\)</span> with <span class="math inline">\(g &lt; n\)</span>. The number <span class="math inline">\(k\)</span> is less than <span class="math inline">\(m\)</span> in all inputs, so <span class="math inline">\(k^w\)</span> is coprime with <span class="math inline">\(m\)</span>. And in the first few subtasks, <span class="math inline">\(w\)</span> is also less than <span class="math inline">\(m\)</span>, so all factors in <span class="math inline">\(\binom{w}{g}\)</span> are all coprime as well. Finally, in the subtasks where <span class="math inline">\(w\)</span> is very large, recall that we're only computing the first <span class="math inline">\(n\)</span> terms of row <span class="math inline">\(w\)</span> of the binomial coefficient table, and that we're using the recurrence <span class="math display">\[\binom{w}{g} = \binom{w}{g - 1}\cdot \frac{w - g + 1}{g},\]</span> so we only need to divide with numbers <span class="math inline">\(g &lt; n\)</span>. Since <span class="math inline">\(n &lt; m\)</span> for all inputs, this is ok too.</p>
<p>Thus, we can safely divide whenever we need to, and all is well in the world.</p>
<p></details></p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>technically, we should say “<em>uniformly randomly, and independently of each other</em>” here...<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>technically, <em>independent</em> doesn't really mean <em>has nothing to do with each other</em>; it means more like <em>the probabilities of one are not affected if you know the other</em><a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>and even if it isn't, the overhead of having to compute with large numbers makes things slower, which we probably couldn't afford for later subtasks<a href="#fnref3">↩</a></p></li>
</ol>
</div>
</div>

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL" crossorigin="anonymous"></script>

</body>
</html>
